<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Shweta Mahajan</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Shweta Mahajan" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YS61FLXW9V"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-YS61FLXW9V');
</script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <h1>
                Shweta Mahajan
              </h1>
              <p> I am a Machine Learning Researcher at Qualcomm AI Research. I was a postdoctoral researcher and a <a href="https://vectorinstitute.ai/">Vector Postdoctoral Affiliate</a> in the <a href="https://vision.cs.ubc.ca/">Vision Group</a> at <a href="https://www.ubc.ca/">University of British Columbia</a> advised by <a href="https://www.cs.ubc.ca/~lsigal/">Prof. Leonid Sigal</a> and <a href="https://www.cs.ubc.ca/~kmyi/">Prof. Kwang Moo Yi</a>. My research at UBC is focussed on diffusion models for high-level as well as low-level computer vision.
                I obtained my Ph.D. under the supervision of <a href="https://www.visinf.tu-darmstadt.de/visinf/team_members/sroth/sroth.en.jsp">Prof. Stefan Roth, Ph.D.</a> in the <a href="http://www.visinf.tu-darmstadt.de/visinf/news/index.en.jsp">Visual Inference Group</a>, <a href="http://www.tu-darmstadt.de/index.en.jsp">Technische Universit√§t Darmstadt</a>.
                During my Ph.D., I researched deep generative algorithms for multimodal representation learning and the efficiency of exact inference deep generative models.
                I received my M.Sc. from the <a href="https://www.uni-saarland.de/en/department/computer-science.html"> Saarland University</a> where I was a part of the  <a href="https://www.ml.uni-saarland.de/index.html">Machine Learning Group</a> and the <a href="https://www.mpi-inf.mpg.de/home">Max Planck Institute of Informatics</a>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:shweta.nith@outlook.com">Email</a> &nbsp;/&nbsp;
                <a href="/pdfs/cv.pdf">CV</a>  &nbsp;/&nbsp;
                <a href="https://scholar.google.de/citations?user=DUKzkPMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/shweta-mahajan-4808a017/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_img.png">
            </td>
          </tr>
        </table>


<!-- News -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul>
              <li>02/2024: Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models accepted at CVPR 2024. </li>
              <li>02/2024: ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models accepted at CVPR 2024. </li>
              <li>02/2024: Unsupervised Keypoints from Pretrained Diffusion Models accepted at CVPR 2024. </li>
              <li>11/2023: Recognized as a Top Reviewer at NeurIPS 2023! </li>
              <li>09/2023: Talk on Multimodal Representation Learning with Deep Generative Models at NTU Singapore.</li>
              <li>09/2023: Unsupervised Semantic Correspondence Using Stable Diffusion accepted at NeurIPS 2023.</li>
              <li>08/2023: Nominated for the GI-Dissertationspreis!</li>
              <li>07/2023: Awarded research grant by the Vector Institute of Artificial Intelligence!</li> 
              <li>06/2023: Invited to the doctoral consortium at CVPR 2023!</li> 
              <li>06/2023: Nominated for the Bertha Benz Best Thesis Award in Germany!</li> 
              <li>02/2023: Make-A-Story: Visual Memory Conditioned Consistent Story Generation accepted at CVPR 2023.</li> 
              <li>10/2022: I have joined UBC as a postdoctoral researcher.</li> 
              <li>06/2022: I have successfully defended my Ph.D. dissertation (summa cum laude)!</li> 
              </ul>
            </td>
          </tr>
        </table>

<!-- Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I am interested in computer vision and machine learning, specifically in deep generative models (diffusion models, normalizing flows, variational methods, GANs) for multimodal representation learning. 
              </p>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr onmouseout="storyldm_stop()" onmouseover="storyldm_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='storyldm_mouseover'>
                <img src=/images/ph2p_2023.png width="180"></div>
                <img src=/images/ph2p_2023.png width="180">
              </div>
              <script type="text/javascript">
                function storyldm_start() {
                  document.getElementById('storyldm_mouseover').style.opacity = "1";
                }
                function storyldm_stop() {
                  document.getElementById('storyldm_mouseover').style.opacity = "0";
                }
                storyldm_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
               <a href="https://arxiv.org/pdf/2312.12416.pdf"><h3>Prompting Hard or Hardly Prompting:
Prompt Inversion for Text-to-Image Diffusion Models</h3></a>
              <br>
              <b>Shweta Mahajan</b>, Tanzila Rahman, Kwang Moo Yi, Leonid Sigal
              <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2312.12416">paper</a> / 
              <a href=https://arxiv.org/pdf/2312.12416">arxiv</a> 
              <p> Inverting the diffusion model to obtain interpretable language prompts directly based on the findings that different timesteps of the diffusion process cater to different levels of detail in an image.</p>
            </td>
          </tr>
          <tr onmouseout="storyldm_stop()" onmouseover="storyldm_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='storyldm_mouseover'>
                <img src=/images/vivid_2023.png width="180"></div>
                <img src=/images/vivid_2023.png width="180">
              </div>
              <script type="text/javascript">
                function storyldm_start() {
                  document.getElementById('storyldm_mouseover').style.opacity = "1";
                }
                function storyldm_stop() {
                  document.getElementById('storyldm_mouseover').style.opacity = "0";
                }
                storyldm_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
               <a href="https://arxiv.org/pdf/2312.01305"><h3>ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models</h3></a>
              <br>
              Jeong-gi Kwak, Erqun Dong, Yuhe Jin, Hanseok Ko, <b>Shweta Mahajan</b>, Kwang Moo Yi
              <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2312.01305">paper</a> / 
              <a href=https://arxiv.org/pdf/2312.01305">arxiv</a> / 
              <a href="https://jgkwak95.github.io/ViVid-1-to-3/">code</a> / 
              <p> We utilize a pre-trained video diffusion model to solve consistency in zero-shot view synthesis.</p>
            </td>
          </tr>
           <tr onmouseout="storyldm_stop()" onmouseover="storyldm_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='storyldm_mouseover'>
                <img src=/images/unsup_keypoints_2023.png width="180"></div>
                <img src=/images/unsup_keypoints_2023.png width="180">
              </div>
              <script type="text/javascript">
                function storyldm_start() {
                  document.getElementById('storyldm_mouseover').style.opacity = "1";
                }
                function storyldm_stop() {
                  document.getElementById('storyldm_mouseover').style.opacity = "0";
                }
                storyldm_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
               <a href="https://arxiv.org/pdf/2312.00065.pdf"><h3>Unsupervised Keypoints from Pretrained Diffusion Models</h3></a>
              <br>
              Eric Hedlin, Gopal Sharma, <b>Shweta Mahajan</b>, Xingzhe He, Hossam Isack, Abhishek Kar Helge Rhodin, Andrea Tagliasacchi, Kwang Moo Yi
              <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2312.00065">paper</a> / 
              <a href="https://arxiv.org/pdf/2312.00065">arxiv</a> / 
              <a href="https://stablekeypoints.github.io/">code</a> / 
              <p> One can leverage this semantic knowledge within diffusion models to find key points across images of similar kind.</p>
            </td>
          </tr>

          
          <tr onmouseout="storyldm_stop()" onmouseover="storyldm_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='storyldm_mouseover'>
                <img src=/images/neurips_2023.png width="180"></div>
                <img src=/images/neurips_2023.png width="180">
              </div>
              <script type="text/javascript">
                function storyldm_start() {
                  document.getElementById('storyldm_mouseover').style.opacity = "1";
                }
                function storyldm_stop() {
                  document.getElementById('storyldm_mouseover').style.opacity = "0";
                }
                storyldm_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
               <a href="https://arxiv.org/pdf/2305.15581.pdf"><h3>Unsupervised Semantic Correspondence Using Stable Diffusion</h3></a>
              <br>
              Eric Hedlin, Gopal Sharma, <b>Shweta Mahajan</b>, Hossam Isack, Abhishek Kar, Andrea Tagliasacchi, Kwang Moo Yi
              <br>
              <em>NeurIPS</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2305.15581.pdf">paper</a> / 
              <a href="https://arxiv.org/pdf/2305.15581.pdf">arxiv</a> / 
              <a href="https://github.com/ubc-vision/LDM_correspondences">code</a> / 
              <p> One can leverage this semantic knowledge within diffusion models to find semantic correspondences with prompt optimization.</p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr onmouseout="storyldm_stop()" onmouseover="storyldm_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='storyldm_mouseover'>
                <img src=/images/cvpr_2023.png width="180"></div>
                <img src=/images/cvpr_2023.png width="180">
              </div>
              <script type="text/javascript">
                function storyldm_start() {
                  document.getElementById('storyldm_mouseover').style.opacity = "1";
                }
                function storyldm_stop() {
                  document.getElementById('storyldm_mouseover').style.opacity = "0";
                }
                storyldm_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
               <a href="https://arxiv.org/pdf/2211.13319.pdf"><h3>Make-A-Story: Visual Memory Conditioned Consistent Story Generation</h3></a>
              <br>
              Tanzila Rahman, Hsin-Ying Lee, Jian Ren, Sergey Tulyakov, <b>Shweta Mahajan</b> and Leonid Sigal
              <br>
              <em>CVPR</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2211.13319.pdf">paper</a> / 
              <a href="https://arxiv.org/pdf/2211.13319.pdf">arxiv</a> / 
              <p> Sentence-conditioned soft attention over the memories enables effective reference resolution and learns to maintain scene and actor consistency
when needed.</p>

            </td>
          </tr>

           <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr onmouseout="thesis_stop()" onmouseover="thesis_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='storyldm_mouseover'>
                <img src=/images/thesis.png width="180"></div>
                <img src=/images/thesis.png width="180">
              </div>
              <script type="text/javascript">
                function thesis_start() {
                  document.getElementById('storyldm_mouseover').style.opacity = "1";
                }
                function thesis_stop() {
                  document.getElementById('storyldm_mouseover').style.opacity = "0";
                }
                thesis_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
               <a href="https://tuprints.ulb.tu-darmstadt.de/21651/1/mahajan-phd.pdf"><h3>Multimodal Representation Learning for Diverse Synthesis with Deep Generative Models</h3></a>
              <br>
              <b>Shweta Mahajan</b>
              <br>
              <em>Ph.D. Thesis</em>, 2022
              <br>
              <a href="https://tuprints.ulb.tu-darmstadt.de/21651/">Thesis</a> 
            </td>
          </tr>
          
          <tr onmouseout="styleseqcvae_stop()" onmouseover="styleseqcvae_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='styleseqcvae_mouseover'>
                <img src=/images/gcpr_2021.png width="180"></div>
                <img src=/images/gcpr_2021.png width="180">
              </div>
              <script type="text/javascript">
                function styleseqcvae_start() {
                  document.getElementById('styleseqcvae_mouseover').style.opacity = "1";
                }
                function styleseqcvae_stop() {
                  document.getElementById('styleseqcvae_mouseover').style.opacity = "0";
                }
                styleseqcvae_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
               <a href="https://arxiv.org/pdf/2205.01813.pdf"><h3>Diverse Image Captioning with Grounded Style</h3></a>
              <br>
              Franz Klein, <b>Shweta Mahajan</b> and Stefan Roth
              <br>
              <em>GCPR</em>, 2021
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-92659-5_27">paper</a> / 
              <a href="https://arxiv.org/pdf/2205.01813.pdf">arxiv</a> / 
              <a href="https://github.com/visinf/style-seqcvae">code</a>
              <p>A sequential variational framework encoding the style information grounded in images for stylized image captioning.</p>

            </td>
          </tr>

          <tr onmouseout="pixelpyramids_stop()" onmouseover="pixelpyramids_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='pixelpyramids_mouseover'>
                <img src=/images/iccv_2021.png width="180"></div>
                <img src=/images/iccv_2021.png width="180">
              </div>
              <script type="text/javascript">
                function pixelpyramids_start() {
                  document.getElementById('pixelpyramids_mouseover').style.opacity = "1";
                }
                function pixelpyramids_stop() {
                  document.getElementById('pixelpyramids_mouseover').style.opacity = "0";
                }
                pixelpyramids_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Mahajan_PixelPyramids_Exact_Inference_Models_From_Lossless_Image_Pyramids_ICCV_2021_paper.html"><h3>PixelPyramids: Exact Inference Models from Lossless Image Pyramids</h3></a>
              <br>
              <b>Shweta Mahajan</b> and Stefan Roth
              <br>
              <em>ICCV</em>, 2021
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Mahajan_PixelPyramids_Exact_Inference_Models_From_Lossless_Image_Pyramids_ICCV_2021_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Mahajan_PixelPyramids_Exact_Inference_ICCV_2021_supplemental.pdf">supp</a> / 
              <a href="http://arxiv.org/abs/2110.08787">arxiv</a> / 
              <a href="https://www.youtube.com/watch?v=Dd3U1677-B8&t=219s">video</a> /
              <a href="https://github.com/visinf/pixelpyramids">code</a>
              <p>A block-autoregressive exact inference model employing a lossless pyramid decomposition with scale-specific representations to encode the joint distribution of image pixels.</p>

            </td>
          </tr>
          
          <tr onmouseout="coscvae_stop()" onmouseover="coscvae_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='coscvae_mouseover'>
                <img src=/images/neurips_2020.png width="180"></div>
                <img src=/images/neurips_2020.png width="180">
              </div>
              <script type="text/javascript">
                function coscvae_start() {
                  document.getElementById('coscvae_mouseover').style.opacity = "1";
                }
                function coscvae_stop() {
                  document.getElementById('coscvae_mouseover').style.opacity = "0";
                }
                coscvae_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://proceedings.neurips.cc/paper/2020/hash/24bea84d52e6a1f8025e313c2ffff50a-Abstract.html"><h3>Diverse Image Captioning with Context-Object Split Latent Spaces</h3></a>
              <br>
              <b>Shweta Mahajan</b> and Stefan Roth
              <br>
              <em>NeurIPS</em>, 2020<font color="#FA4841"></font>
              <br>
              <a href="https://proceedings.neurips.cc//paper/2020/file/24bea84d52e6a1f8025e313c2ffff50a-Paper.pdf">paper</a> / 
              <a href="https://proceedings.neurips.cc/paper/2020/file/24bea84d52e6a1f8025e313c2ffff50a-Supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/2011.00966">arxiv</a> / 
              <a href="https://www.youtube.com/watch?v=2APHCFsRowI">video</a> /
              <a href="https://github.com/visinf/cos-cvae">code</a> 
              <p>We introduce a novel factorization of the latent space to model diversity in contextual descriptions across images and texts within the dataset.</p>

            </td>
          </tr>
          
          
          <tr onmouseout="marscf_stop()" onmouseover="marscf_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='marscf_mouseover'>
                <img src=/images/cvpr_2020.png width="180"></div>
                <img src=/images/cvpr_2020.png width="180">
              </div>
              <script type="text/javascript">
                function marscf_start() {
                  document.getElementById('marscf_mouseover').style.opacity = "1";
                }
                function marscf_stop() {
                  document.getElementById('marscf_mouseover').style.opacity = "0";
                }
                marscf_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Bhattacharyya_Normalizing_Flows_With_Multi-Scale_Autoregressive_Priors_CVPR_2020_paper.html"><h3>Normalizing Flows with Multi-Scale Autoregressive Priors</h3></a>
              <br>
              <b>Shweta Mahajan*</b>, Apratim Bhattacharyya*, Mario Fritz, Bernt Schiele and Stefan Roth
              <br>
              <em>CVPR</em>, 2020
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Bhattacharyya_Normalizing_Flows_With_Multi-Scale_Autoregressive_Priors_CVPR_2020_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Bhattacharyya_Normalizing_Flows_With_CVPR_2020_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/2004.03891">arxiv</a> / 
              <a href="https://www.youtube.com/watch?v=wSRFZ-oMWEE">video</a> /
              <a href="https://github.com/visinf/mar-scf">code</a>
              <p>We improve the representational power of flow-based models by introducing channel-wise dependencies in their latent space through multi-scale autoregressive priors.</p>

            </td>
          </tr>
          
          <tr onmouseout="lnfmm_stop()" onmouseover="lnfmm_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='lnfmm_mouseover'>
                <img src=/images/iclr_2020.png width="180"></div>
                <img src=/images/iclr_2020.png width="180">
              </div>
              <script type="text/javascript">
                function lnfmm_start() {
                  document.getElementById('lnfmm_mouseover').style.opacity = "1";
                }
                function lnfmm_stop() {
                  document.getElementById('lnfmm_mouseover').style.opacity = "0";
                }
                lnfmm_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openreview.net/forum?id=SJxE8erKDH"><h3>Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings</h3></a>
              <br>
              <b>Shweta Mahajan</b>, Iryna Gurevych and Stefan Roth
              <br>
              <em>ICLR</em>, 2020 (<font color="#FA4841"><b>Best Paper Award</b></font>, Fraunhofer IGD)
              <br>
              <a href="https://openreview.net/pdf?id=SJxE8erKDH">paper</a> / 
              <a href="https://arxiv.org/abs/2002.06661">arxiv</a> / 
              <a href="https://www.youtube.com/watch?v=oUE3fBs3CaQ">video</a> /
              <a href="https://github.com/visinf/lnfmm">code</a>
              <p>Our model integrates normalizing flow-based priors for the domain-specific information, which allows us to learn diverse many-to-many mappings between the image and text domains.</p>

            </td>
          </tr>
          
          <tr onmouseout="jwae_stop()" onmouseover="jwae_start()">
            <td style="padding:2.0%;width:25%;vertical-align:middle">
              <div class="one" style="width:auto; height:auto; max-width:100%;">
                <div class="two" style="width:auto; height:auto; max-width:100%;" id='jwae_mouseover'>
                <img src=/images/iccvw_2019.png width="180"></div>
                <img src=/images/iccvw_2019.png .png width="180">
              </div>
              <script type="text/javascript">
                function jwae_start() {
                  document.getElementById('jwae_mouseover').style.opacity = "1";
                }
                function jwae_stop() {
                  document.getElementById('jwae_mouseover').style.opacity = "0";
                }
                jwae_stop()
              </script>
            </td>
            <td style="padding:2.0%;width:75%;vertical-align:middle">              
              <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CROMOL/Mahajan_Joint_Wasserstein_Autoencoders_for_Aligning_Multimodal_Embeddings_ICCVW_2019_paper.pdf"><h3>Joint Wasserstein Autoencoders for Aligning Multimodal Embeddings</h3></a>
              <br>
              <b>Shweta Mahajan</b>, Teresa Botschen, Iryna Gurevych and Stefan Roth
              <br>
              <em>ICCV Workshops</em>, 2019 (<font color="#FA4841"><b>Oral presentation</b></font>)
              <br>
              <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CROMOL/Mahajan_Joint_Wasserstein_Autoencoders_for_Aligning_Multimodal_Embeddings_ICCVW_2019_paper.pdf">paper</a> /  
              <a href="https://arxiv.org/abs/1909.06635">arxiv</a> 
              <p>We propose joint Gaussian regularization of the latent representations to ensure coherent cross-modal semantics that generalize across datasets.</p>

            </td>
          </tr>
       </table>
        <br>
        <br>
      </td>
    </tr>
  </table>
</body>

</html>

